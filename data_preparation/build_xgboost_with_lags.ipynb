{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from division_aggregation_function import division_aggregation\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/covid_data1.csv\", index_col=0)\n",
    "df['region'] = df['location_key'].apply(division_aggregation)\n",
    "df = df[df.columns[(df.isna().sum()/len(df) <= 0.1).values]]\n",
    "df['date'] = pd.to_datetime(df.date)\n",
    "df['year'] = df.date.dt.year\n",
    "df['month'] = df.date.dt.month\n",
    "df['day'] = df.date.dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = df[['date', 'region', 'location_key', 'new_confirmed']]\n",
    "x_data = df.drop(columns = ['date', 'new_confirmed'])\n",
    "xddum = pd.get_dummies(x_data)\n",
    "scaler = StandardScaler()\n",
    "scaledx = scaler.fit_transform(xddum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "datanum = scaledx.copy()\n",
    "knn = KNNImputer(n_neighbors = 10)\n",
    "imputedvals2 = knn.fit_transform(datanum)\n",
    "knn_datanum = pd.DataFrame(imputedvals2, columns = xddum.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdatanew = pd.DataFrame(scaler.inverse_transform(knn_datanum), columns = xddum.columns)\n",
    "xdata_other = xdatanew.drop(columns = xdatanew.columns[-63:])\n",
    "xdata_xg = xdatanew.drop(columns = xdatanew.columns[-9:])\n",
    "data_all = pd.concat([y_data, xdata_other], axis = 1)\n",
    "data_xg = pd.concat([y_data, xdata_xg], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_columns(df):\n",
    "    for col in df.columns:\n",
    "        if col.startswith('location_key_'):\n",
    "            df[col] = df[col].round().astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multivariate\n",
    "enc_data_multi = data_xg[data_xg['region'] == \"East North Central\"]\n",
    "esc_data_multi = data_xg[data_xg['region'] == \"East South Central\"]\n",
    "mid_atlantic_data_multi = data_xg[data_xg['region'] == \"Mid-Atlantic\"]\n",
    "mountain_data_multi = data_xg[data_xg['region'] == \"Mountain\"]\n",
    "new_england_data_multi = data_xg[data_xg['region'] == \"New England\"]\n",
    "pacific_data_multi = data_xg[data_xg['region'] == \"Pacific\"]\n",
    "south_atlantic_data_multi = data_xg[data_xg['region'] == \"South Atlantic\"]\n",
    "wnc_data_multi = data_xg[data_xg['region'] == \"West North Central\"]\n",
    "wsc_data_multi = data_xg[data_xg['region'] == \"West South Central\"]\n",
    "\n",
    "# Round location_key columns\n",
    "enc_data_multi = round_columns(enc_data_multi)\n",
    "esc_data_multi = round_columns(esc_data_multi)\n",
    "mid_atlantic_data_multi = round_columns(mid_atlantic_data_multi)\n",
    "mountain_data_multi = round_columns(mountain_data_multi)\n",
    "new_england_data_multi = round_columns(new_england_data_multi)\n",
    "pacific_data_multi = round_columns(pacific_data_multi)\n",
    "south_atlantic_data_multi = round_columns(south_atlantic_data_multi)\n",
    "wnc_data_multi = round_columns(wnc_data_multi)\n",
    "wsc_data_multi = round_columns(wsc_data_multi)\n",
    "\n",
    "# Drop columns with all zeros i.e. empty state columns\n",
    "enc_data_multi = enc_data_multi.loc[:, ~(enc_data_multi == 0).all()]\n",
    "esc_data_multi = esc_data_multi.loc[:, ~(esc_data_multi == 0).all()]\n",
    "mid_atlantic_data_multi = mid_atlantic_data_multi.loc[:, ~(mid_atlantic_data_multi == 0).all()]\n",
    "mountain_data_multi = mountain_data_multi.loc[:, ~(mountain_data_multi == 0).all()]\n",
    "new_england_data_multi = new_england_data_multi.loc[:, ~(new_england_data_multi == 0).all()]\n",
    "pacific_data_multi = pacific_data_multi.loc[:, ~(pacific_data_multi == 0).all()]\n",
    "south_atlantic_data_multi = south_atlantic_data_multi.loc[:, ~(south_atlantic_data_multi == 0).all()]\n",
    "wnc_data_multi = wnc_data_multi.loc[:, ~(wnc_data_multi == 0).all()]\n",
    "wsc_data_multi = wsc_data_multi.loc[:, ~(wsc_data_multi == 0).all()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transformations(df):\n",
    "    all_lags = {\"Pacific\": [1, 3, 7, 10], \"East North Central\": [1, 2, 7], \n",
    "                \"East South Central\": [1, 2, 3, 7], \"Mid-Atlantic\": [1, 2, 8, 9], \n",
    "                \"Mountain\": [1, 6, 7], \"New England\": [1, 7], \"South Atlantic\": [1, 6, 7], \n",
    "                \"West North Central\": [1, 6, 7], \"West South Central\": [1, 7]}\n",
    "\n",
    "    region = df.region.unique()[0]\n",
    "    lags = all_lags.get(region, [])\n",
    "    # Create lagged features\n",
    "    for i in lags:\n",
    "        df[str(i) + \"_day_shift\"] = df['new_confirmed'].shift(i)\n",
    "    \n",
    "    # Compute 7-day moving average\n",
    "    df[\"7_day_avg\"] = df['new_confirmed'].rolling(window=7).mean()\n",
    "    return df\n",
    "\n",
    "pacific_data_multi.sort_values(by=['location_key', 'date'], inplace=True)\n",
    "pacific_data_multi = pacific_data_multi.groupby('location_key').apply(apply_transformations)\n",
    "\n",
    "enc_data_multi.sort_values(by=['location_key', 'date'], inplace=True)\n",
    "enc_data_multi = enc_data_multi.groupby('location_key').apply(apply_transformations)\n",
    "\n",
    "esc_data_multi.sort_values(by=['location_key', 'date'], inplace=True)\n",
    "esc_data_multi = esc_data_multi.groupby('location_key').apply(apply_transformations)\n",
    "\n",
    "mid_atlantic_data_multi.sort_values(by=['location_key', 'date'], inplace=True)\n",
    "mid_atlantic_data_multi = mid_atlantic_data_multi.groupby('location_key').apply(apply_transformations)\n",
    "\n",
    "mountain_data_multi.sort_values(by=['location_key', 'date'], inplace=True)\n",
    "mountain_data_multi = mountain_data_multi.groupby('location_key').apply(apply_transformations)\n",
    "\n",
    "new_england_data_multi.sort_values(by=['location_key', 'date'], inplace=True)\n",
    "new_england_data_multi = new_england_data_multi.groupby('location_key').apply(apply_transformations)\n",
    "\n",
    "south_atlantic_data_multi.sort_values(by=['location_key', 'date'], inplace=True)\n",
    "south_atlantic_data_multi = south_atlantic_data_multi.groupby('location_key').apply(apply_transformations)\n",
    "\n",
    "wnc_data_multi.sort_values(by=['location_key', 'date'], inplace=True)\n",
    "wnc_data_multi = wnc_data_multi.groupby('location_key').apply(apply_transformations)\n",
    "\n",
    "wsc_data_multi.sort_values(by=['location_key', 'date'], inplace=True)\n",
    "wsc_data_multi = wsc_data_multi.groupby('location_key').apply(apply_transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacific_data_multi.to_csv('../data/regional_datasets/xgboost/pacific_data_multi.csv')\n",
    "enc_data_multi.to_csv('../data/regional_datasets/xgboost/enc_data_multi.csv')\n",
    "esc_data_multi.to_csv('../data/regional_datasets/xgboost/esc_data_multi.csv')\n",
    "mid_atlantic_data_multi.to_csv('../data/regional_datasets/xgboost/mid_atlantic_data_multi.csv')\n",
    "mountain_data_multi.to_csv('../data/regional_datasets/xgboost/mountain_data_multi.csv')\n",
    "new_england_data_multi.to_csv('../data/regional_datasets/xgboost/new_england_data_multi.csv')\n",
    "south_atlantic_data_multi.to_csv('../data/regional_datasets/xgboost/south_atlantic_data_multi.csv')\n",
    "wnc_data_multi.to_csv('../data/regional_datasets/xgboost/wnc_data_multi.csv')\n",
    "wsc_data_multi.to_csv('../data/regional_datasets/xgboost/wsc_data_multi.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3827201b074f3d400d73203a56a627ff3396f8ee111eb12af9c3a231c9d93aab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
