{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from division_aggregation_function import division_aggregation\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/covid_data1.csv\", index_col=0)\n",
    "df['region'] = df['location_key'].apply(division_aggregation)\n",
    "df = df[df.columns[(df.isna().sum()/len(df) <= 0.1).values]]\n",
    "df['date'] = pd.to_datetime(df.date)\n",
    "df['year'] = df.date.dt.year\n",
    "df['month'] = df.date.dt.month\n",
    "df['day'] = df.date.dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>location_key</th>\n",
       "      <th>new_confirmed</th>\n",
       "      <th>new_deceased</th>\n",
       "      <th>cumulative_confirmed</th>\n",
       "      <th>cumulative_deceased</th>\n",
       "      <th>new_hospitalized_patients</th>\n",
       "      <th>cumulative_hospitalized_patients</th>\n",
       "      <th>current_hospitalized_patients</th>\n",
       "      <th>current_intensive_care_patients</th>\n",
       "      <th>...</th>\n",
       "      <th>new_vaccine_doses_administered_moderna</th>\n",
       "      <th>cumulative_vaccine_doses_administered_moderna</th>\n",
       "      <th>new_persons_fully_vaccinated_janssen</th>\n",
       "      <th>cumulative_persons_fully_vaccinated_janssen</th>\n",
       "      <th>new_vaccine_doses_administered_janssen</th>\n",
       "      <th>cumulative_vaccine_doses_administered_janssen</th>\n",
       "      <th>region</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>US_AK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>US_AK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>US_AK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-09</td>\n",
       "      <td>US_AK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>US_AK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date location_key  new_confirmed  new_deceased  cumulative_confirmed  \\\n",
       "0 2020-03-06        US_AK            0.0           0.0                   0.0   \n",
       "1 2020-03-07        US_AK            0.0           0.0                   0.0   \n",
       "2 2020-03-08        US_AK            0.0           0.0                   0.0   \n",
       "3 2020-03-09        US_AK            0.0           0.0                   0.0   \n",
       "4 2020-03-10        US_AK            0.0           0.0                   0.0   \n",
       "\n",
       "   cumulative_deceased  new_hospitalized_patients  \\\n",
       "0                  0.0                        0.0   \n",
       "1                  0.0                        0.0   \n",
       "2                  0.0                        0.0   \n",
       "3                  0.0                        1.0   \n",
       "4                  0.0                        0.0   \n",
       "\n",
       "   cumulative_hospitalized_patients  current_hospitalized_patients  \\\n",
       "0                               NaN                            NaN   \n",
       "1                               NaN                            NaN   \n",
       "2                               NaN                            NaN   \n",
       "3                               1.0                            NaN   \n",
       "4                               1.0                            NaN   \n",
       "\n",
       "   current_intensive_care_patients  ...  \\\n",
       "0                              NaN  ...   \n",
       "1                              NaN  ...   \n",
       "2                              NaN  ...   \n",
       "3                              NaN  ...   \n",
       "4                              NaN  ...   \n",
       "\n",
       "   new_vaccine_doses_administered_moderna  \\\n",
       "0                                     0.0   \n",
       "1                                     0.0   \n",
       "2                                     0.0   \n",
       "3                                     0.0   \n",
       "4                                     0.0   \n",
       "\n",
       "   cumulative_vaccine_doses_administered_moderna  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "\n",
       "   new_persons_fully_vaccinated_janssen  \\\n",
       "0                                   0.0   \n",
       "1                                   0.0   \n",
       "2                                   0.0   \n",
       "3                                   0.0   \n",
       "4                                   0.0   \n",
       "\n",
       "   cumulative_persons_fully_vaccinated_janssen  \\\n",
       "0                                          0.0   \n",
       "1                                          0.0   \n",
       "2                                          0.0   \n",
       "3                                          0.0   \n",
       "4                                          0.0   \n",
       "\n",
       "   new_vaccine_doses_administered_janssen  \\\n",
       "0                                     0.0   \n",
       "1                                     0.0   \n",
       "2                                     0.0   \n",
       "3                                     0.0   \n",
       "4                                     0.0   \n",
       "\n",
       "   cumulative_vaccine_doses_administered_janssen   region  year  month  day  \n",
       "0                                            0.0  Pacific  2020      3    6  \n",
       "1                                            0.0  Pacific  2020      3    7  \n",
       "2                                            0.0  Pacific  2020      3    8  \n",
       "3                                            0.0  Pacific  2020      3    9  \n",
       "4                                            0.0  Pacific  2020      3   10  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = df[['date', 'region', 'location_key', 'new_confirmed']]\n",
    "x_data = df.drop(columns = ['date', 'new_confirmed'])\n",
    "xddum = pd.get_dummies(x_data)\n",
    "scaler = StandardScaler()\n",
    "scaledx = scaler.fit_transform(xddum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "datanum = xddum.copy()\n",
    "mice = IterativeImputer(max_iter = 50, random_state = 0)\n",
    "imputedvals = mice.fit_transform(datanum)\n",
    "imputed_datanum1 = pd.DataFrame(imputedvals, columns = xddum.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "datanum = scaledx.copy()\n",
    "knn = KNNImputer(n_neighbors = 10)\n",
    "imputedvals2 = knn.fit_transform(datanum)\n",
    "knn_datanum = pd.DataFrame(imputedvals2, columns = xddum.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdatanew = pd.DataFrame(scaler.inverse_transform(knn_datanum), columns = xddum.columns)\n",
    "xdata_other = xdatanew.drop(columns = xdatanew.columns[-63:])\n",
    "xdata_xg = xdatanew.drop(columns = xdatanew.columns[-9:])\n",
    "data_all = pd.concat([y_data, xdata_other], axis = 1)\n",
    "data_xg = pd.concat([y_data, xdata_xg], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multivariate\n",
    "enc_data_multi = data_xg[data_xg['region'] == \"East North Central\"]\n",
    "esc_data_multi = data_xg[data_xg['region'] == \"East South Central\"]\n",
    "mid_atlantic_data_multi = data_xg[data_xg['region'] == \"Mid-Atlantic\"]\n",
    "mountain_data_multi = data_xg[data_xg['region'] == \"Mountain\"]\n",
    "new_england_data_multi = data_xg[data_xg['region'] == \"New England\"]\n",
    "pacific_data_multi = data_xg[data_xg['region'] == \"Pacific\"]\n",
    "south_atlantic_data_multi = data_xg[data_xg['region'] == \"South Atlantic\"]\n",
    "wnc_data_multi = data_xg[data_xg['region'] == \"West North Central\"]\n",
    "wsc_data_multi = data_xg[data_xg['region'] == \"West South Central\"]\n",
    "\n",
    "enc_data_multi = enc_data_multi.loc[:, ~(enc_data_multi == 0).all()]\n",
    "esc_data_multi = esc_data_multi.loc[:, ~(esc_data_multi == 0).all()]\n",
    "mid_atlantic_data_multi = mid_atlantic_data_multi.loc[:, ~(mid_atlantic_data_multi == 0).all()]\n",
    "mountain_data_multi = mountain_data_multi.loc[:, ~(mountain_data_multi == 0).all()]\n",
    "new_england_data_multi = new_england_data_multi.loc[:, ~(new_england_data_multi == 0).all()]\n",
    "pacific_data_multi = pacific_data_multi.loc[:, ~(pacific_data_multi == 0).all()]\n",
    "south_atlantic_data_multi = south_atlantic_data_multi.loc[:, ~(south_atlantic_data_multi == 0).all()]\n",
    "wnc_data_multi = wnc_data_multi.loc[:, ~(wnc_data_multi == 0).all()]\n",
    "wsc_data_multi = wsc_data_multi.loc[:, ~(wsc_data_multi == 0).all()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacific_lag = [1, 3, 7, 10]\n",
    "enc_lag = [1, 2, 7]\n",
    "esc_lag = [1, 2, 3, 7]\n",
    "mid_atlantic_lag = [1, 2, 8, 9]\n",
    "mountain_lag = [1, 6, 7]\n",
    "new_england_lag = [1, 7]\n",
    "south_atlantic_lag = [1, 6, 7]\n",
    "wnc_lag = [1, 6, 7]\n",
    "wsc_lag = [1, 7]\n",
    "\n",
    "for i in pacific_lag:\n",
    "    pacific_data_multi[str(i) + \"_day_shift\"] = pacific_data_multi['new_confirmed'].shift(i)\n",
    "    pacific_data_multi[\"7_day_avg\"] = pacific_data_multi['new_confirmed'].rolling(window= 7).mean()\n",
    "\n",
    "for i in enc_lag:\n",
    "    enc_data_multi[str(i) + \"_day_shift\"] = enc_data_multi['new_confirmed'].shift(i)\n",
    "    enc_data_multi[\"7_day_avg\"] = enc_data_multi['new_confirmed'].rolling(window= 7).mean()\n",
    "\n",
    "for i in esc_lag:\n",
    "    esc_data_multi[str(i) + \"_day_shift\"] = esc_data_multi['new_confirmed'].shift(i)\n",
    "    esc_data_multi[\"7_day_avg\"] = esc_data_multi['new_confirmed'].rolling(window= 7).mean()\n",
    "\n",
    "\n",
    "for i in mid_atlantic_lag:\n",
    "    mid_atlantic_data_multi[str(i) + \"_day_shift\"] = mid_atlantic_data_multi['new_confirmed'].shift(i)\n",
    "    mid_atlantic_data_multi[\"7_day_avg\"] = mid_atlantic_data_multi['new_confirmed'].rolling(window= 7).mean()\n",
    "\n",
    "for i in mountain_lag:\n",
    "    mountain_data_multi[str(i) + \"_day_shift\"] = mountain_data_multi['new_confirmed'].shift(i)\n",
    "    mountain_data_multi[\"7_day_avg\"] = mountain_data_multi['new_confirmed'].rolling(window= 7).mean()\n",
    "\n",
    "for i in new_england_lag:\n",
    "    new_england_data_multi[str(i) + \"_day_shift\"] = new_england_data_multi['new_confirmed'].shift(i)\n",
    "    new_england_data_multi[\"7_day_avg\"] = new_england_data_multi['new_confirmed'].rolling(window= 7).mean()\n",
    "\n",
    "for i in south_atlantic_lag:\n",
    "    south_atlantic_data_multi[str(i) + \"_day_shift\"] = south_atlantic_data_multi['new_confirmed'].shift(i)\n",
    "    south_atlantic_data_multi[\"7_day_avg\"] = south_atlantic_data_multi['new_confirmed'].rolling(window= 7).mean()\n",
    "\n",
    "for i in wnc_lag:\n",
    "    wnc_data_multi[str(i) + \"_day_shift\"] = wnc_data_multi['new_confirmed'].shift(i)\n",
    "    wnc_data_multi[\"7_day_avg\"] = wnc_data_multi['new_confirmed'].rolling(window= 7).mean()\n",
    "\n",
    "for i in wsc_lag:\n",
    "    wsc_data_multi[str(i) + \"_day_shift\"] = wsc_data_multi['new_confirmed'].shift(i)\n",
    "    wsc_data_multi[\"7_day_avg\"] = wsc_data_multi['new_confirmed'].rolling(window= 7).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacific_data_multi.to_csv('../data/regional_datasets/xgboost/pacific_data_multi.csv')\n",
    "enc_data_multi.to_csv('../data/regional_datasets/xgboost/enc_data_multi.csv')\n",
    "esc_data_multi.to_csv('../data/regional_datasets/xgboost/esc_data_multi.csv')\n",
    "mid_atlantic_data_multi.to_csv('../data/regional_datasets/xgboost/mid_atlantic_data_multi.csv')\n",
    "mountain_data_multi.to_csv('../data/regional_datasets/xgboost/mountain_data_multi.csv')\n",
    "new_england_data_multi.to_csv('../data/regional_datasets/xgboost/new_england_data_multi.csv')\n",
    "south_atlantic_data_multi.to_csv('../data/regional_datasets/xgboost/south_atlantic_data_multi.csv')\n",
    "wnc_data_multi.to_csv('../data/regional_datasets/xgboost/wnc_data_multi.csv')\n",
    "wsc_data_multi.to_csv('../data/regional_datasets/xgboost/wsc_data_multi.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3827201b074f3d400d73203a56a627ff3396f8ee111eb12af9c3a231c9d93aab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
